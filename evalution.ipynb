{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluation.\n",
    "\n",
    "ksr = (fk - rk) / fk\n",
    " \n",
    " where fk = full keystrokes\n",
    "       rk = responsive keystroke\n",
    "       fk = full keystrokes\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sugartensor as tf\n",
    "import numpy as np\n",
    "from prepro import *\n",
    "from train import ModelGraph\n",
    "import codecs\n",
    "\n",
    "def main(): \n",
    "    g = ModelGraph(mode=\"test\")\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        tf.sg_init(sess)\n",
    "\n",
    "        # restore parameters\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('asset/train'))\n",
    "        print(\"Restored!\")\n",
    "        mname = open('asset/train/checkpoint', 'r').read().split('\"')[1] # model name\n",
    "        \n",
    "        X, Y = load_test_data()\n",
    "        char2idx, idx2char = load_char_vocab()\n",
    "        word2idx, idx2word = load_word_vocab()\n",
    "        \n",
    "        results = []\n",
    "        rk = 0\n",
    "        num_para = 1\n",
    "        num_char = 1\n",
    "        for x, y in zip(X, Y):\n",
    "            stop_counting = False\n",
    "            x = np.concatenate( (np.zeros((Hyperparams.seqlen-1,)), \n",
    "                                 x[-np.count_nonzero(x):]))# lstrip and zero-pad\n",
    "            \n",
    "            para = \"\".join([idx2char[idx] for idx in x])\n",
    "            \n",
    "            chars, targets = [], [] # targets: the word that the char composes\n",
    "            for word in \"\".join(para).split():\n",
    "                chars.append(\" \")\n",
    "                targets.append(word)\n",
    "                for char in word:\n",
    "                    chars.append(char)\n",
    "                    targets.append(word)\n",
    "            \n",
    "            prefix = \"\" \n",
    "            preds = set()\n",
    "            for i, char_target in enumerate(zip(chars, targets)):\n",
    "                char, target = char_target\n",
    "                oov = \"\"\n",
    "                if target not in word2idx: \n",
    "                    oov = \"oov\"\n",
    "                \n",
    "                if i > Hyperparams.seqlen:\n",
    "                    ctx = np.array(x[i - Hyperparams.seqlen:i], np.int32) # \n",
    "                    \n",
    "                    if char == \" \":\n",
    "                        stop_counting = False\n",
    "                        preds = set()\n",
    "                        \n",
    "                    if not stop_counting:\n",
    "                        logits = sess.run(g.logits, {g.x: np.expand_dims(ctx, 0)}) #(1, 20970)\n",
    "                        while 1:\n",
    "                            pred = np.argmax(logits, -1)[0] # (1,)\n",
    "                            if pred in preds:\n",
    "                                logits[:, pred] = -100000000\n",
    "                            else:\n",
    "                                break\n",
    "                        \n",
    "                        rk += 1\n",
    "                        \n",
    "                        predword = idx2word.get(pred)    \n",
    "                        if predword == target: # S\n",
    "                            stop_counting = True\n",
    "                        preds.add(pred)\n",
    "                    \n",
    "                    results.append(u\"{},{},{},{},{},{},{}\".format(num_char, num_para, char, target, oov, predword, rk) )\n",
    "                    num_char += 1\n",
    "            \n",
    "            num_para += 1\n",
    "            \n",
    "        with codecs.open('data/output_{}_rk_{}.csv'.format(mname, rk), 'w', 'utf-8') as fout:\n",
    "            fout.write(\"\\n\".join(results))\n",
    "                                        \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print(\"Done\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
